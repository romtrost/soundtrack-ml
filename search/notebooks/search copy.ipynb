{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15017db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08972a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>album_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>Money Longer</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>Lil Uzi Vert Vs. The World</td>\n",
       "      <td>198944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>Broccoli (feat. Lil Yachty)</td>\n",
       "      <td>DRAM</td>\n",
       "      <td>Big Baby DRAM</td>\n",
       "      <td>225205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>Still Here</td>\n",
       "      <td>Drake</td>\n",
       "      <td>Views</td>\n",
       "      <td>189853</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>You Was Right</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>Lil Uzi Vert Vs. The World</td>\n",
       "      <td>163944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>Don't Hurt Me</td>\n",
       "      <td>DJ Mustard</td>\n",
       "      <td>Don't Hurt Me</td>\n",
       "      <td>192995</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id playlist_name                   track_name   artist_name  \\\n",
       "0        61000          glow                 Money Longer  Lil Uzi Vert   \n",
       "1        61000          glow  Broccoli (feat. Lil Yachty)          DRAM   \n",
       "2        61000          glow                   Still Here         Drake   \n",
       "3        61000          glow                You Was Right  Lil Uzi Vert   \n",
       "4        61000          glow                Don't Hurt Me    DJ Mustard   \n",
       "\n",
       "                   album_name  duration_ms  pos  \n",
       "0  Lil Uzi Vert Vs. The World       198944    0  \n",
       "1               Big Baby DRAM       225205    1  \n",
       "2                       Views       189853    2  \n",
       "3  Lil Uzi Vert Vs. The World       163944    3  \n",
       "4               Don't Hurt Me       192995    4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/romain/Documents/Personal/Projects/Soundtrack_ML/soundtrack-ml/search/data/processed/track_playlist/tracks_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41a2ab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of tracks: 6615091\n",
      "Deduplicated number of tracks: 674043\n",
      "Created sparse embeddings with shape: (674043, 248480)\n",
      "Number of tracks: 674043\n",
      "Vocabulary size: 248480\n",
      "\n",
      "Example vocabulary entries (feature -> index):\n",
      "  ' m': 12630\n",
      "  'mo': 133198\n",
      "  'on': 147503\n",
      "  'ne': 137696\n",
      "  'ey': 94333\n",
      "  'y ': 192497\n",
      "  ' mo': 13035\n",
      "  'mon': 133415\n",
      "  'one': 147756\n",
      "  'ney': 138248\n",
      "  'ey ': 94334\n",
      "  ' mon': 13055\n",
      "  'mone': 133430\n",
      "  'oney': 147796\n",
      "  'ney ': 138249\n",
      "  ' l': 12080\n",
      "  'lo': 127210\n",
      "  'ng': 138450\n",
      "  'ge': 99368\n",
      "  'er': 91743\n",
      "  'r ': 156998\n",
      "  ' lo': 12386\n",
      "  'lon': 127452\n",
      "  'ong': 147813\n",
      "  'nge': 138645\n",
      "  'ger': 99623\n",
      "  'er ': 91744\n",
      "  ' lon': 12407\n",
      "  'long': 127467\n",
      "  'onge': 147833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Deduplicate tracks based on track_name and artist_name\n",
    "data_dedup = data.drop_duplicates(subset=['track_name', 'artist_name'], keep='first').reset_index(drop=True)\n",
    "print(f\"Original number of tracks: {len(data)}\")\n",
    "print(f\"Deduplicated number of tracks: {len(data_dedup)}\")\n",
    "\n",
    "# Create sparse vector embeddings using TF-IDF\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='char_wb',  # Character n-grams to handle track name variations\n",
    "    ngram_range=(2, 4),  # Use 2-4 character n-grams\n",
    "    min_df=1,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# Fit and transform track names to sparse vectors\n",
    "track_names = data_dedup['track_name'].fillna('').astype(str)\n",
    "sparse_embeddings = vectorizer.fit_transform(track_names)\n",
    "\n",
    "print(f\"Created sparse embeddings with shape: {sparse_embeddings.shape}\")\n",
    "print(f\"Number of tracks: {len(track_names)}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Print a few key-value examples from the vocabulary\n",
    "print(\"\\nExample vocabulary entries (feature -> index):\")\n",
    "vocab_items = list(vectorizer.vocabulary_.items())[:30]\n",
    "for feature, idx in vocab_items:\n",
    "    print(f\"  '{feature}': {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f787660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_713376/3241097420.py:18: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading embeddings to Qdrant...\n",
      "Uploaded 10000 / 674043 embeddings...\n",
      "Uploaded 20000 / 674043 embeddings...\n",
      "Uploaded 30000 / 674043 embeddings...\n",
      "Uploaded 40000 / 674043 embeddings...\n",
      "Uploaded 50000 / 674043 embeddings...\n",
      "Uploaded 60000 / 674043 embeddings...\n",
      "Uploaded 70000 / 674043 embeddings...\n",
      "Uploaded 80000 / 674043 embeddings...\n",
      "Uploaded 90000 / 674043 embeddings...\n",
      "Uploaded 100000 / 674043 embeddings...\n",
      "Uploaded 110000 / 674043 embeddings...\n",
      "Uploaded 120000 / 674043 embeddings...\n",
      "Uploaded 130000 / 674043 embeddings...\n",
      "Uploaded 140000 / 674043 embeddings...\n",
      "Uploaded 150000 / 674043 embeddings...\n",
      "Uploaded 160000 / 674043 embeddings...\n",
      "Uploaded 170000 / 674043 embeddings...\n",
      "Uploaded 180000 / 674043 embeddings...\n",
      "Uploaded 190000 / 674043 embeddings...\n",
      "Uploaded 200000 / 674043 embeddings...\n",
      "Uploaded 210000 / 674043 embeddings...\n",
      "Uploaded 220000 / 674043 embeddings...\n",
      "Uploaded 230000 / 674043 embeddings...\n",
      "Uploaded 240000 / 674043 embeddings...\n",
      "Uploaded 250000 / 674043 embeddings...\n",
      "Uploaded 260000 / 674043 embeddings...\n",
      "Uploaded 270000 / 674043 embeddings...\n",
      "Uploaded 280000 / 674043 embeddings...\n",
      "Uploaded 290000 / 674043 embeddings...\n",
      "Uploaded 300000 / 674043 embeddings...\n",
      "Uploaded 310000 / 674043 embeddings...\n",
      "Uploaded 320000 / 674043 embeddings...\n",
      "Uploaded 330000 / 674043 embeddings...\n",
      "Uploaded 340000 / 674043 embeddings...\n",
      "Uploaded 350000 / 674043 embeddings...\n",
      "Uploaded 360000 / 674043 embeddings...\n",
      "Uploaded 370000 / 674043 embeddings...\n",
      "Uploaded 380000 / 674043 embeddings...\n",
      "Uploaded 390000 / 674043 embeddings...\n",
      "Uploaded 400000 / 674043 embeddings...\n",
      "Uploaded 410000 / 674043 embeddings...\n",
      "Uploaded 420000 / 674043 embeddings...\n",
      "Uploaded 430000 / 674043 embeddings...\n",
      "Uploaded 440000 / 674043 embeddings...\n",
      "Uploaded 450000 / 674043 embeddings...\n",
      "Uploaded 460000 / 674043 embeddings...\n",
      "Uploaded 470000 / 674043 embeddings...\n",
      "Uploaded 480000 / 674043 embeddings...\n",
      "Uploaded 490000 / 674043 embeddings...\n",
      "Uploaded 500000 / 674043 embeddings...\n",
      "Uploaded 510000 / 674043 embeddings...\n",
      "Uploaded 520000 / 674043 embeddings...\n",
      "Uploaded 530000 / 674043 embeddings...\n",
      "Uploaded 540000 / 674043 embeddings...\n",
      "Uploaded 550000 / 674043 embeddings...\n",
      "Uploaded 560000 / 674043 embeddings...\n",
      "Uploaded 570000 / 674043 embeddings...\n",
      "Uploaded 580000 / 674043 embeddings...\n",
      "Uploaded 590000 / 674043 embeddings...\n",
      "Uploaded 600000 / 674043 embeddings...\n",
      "Uploaded 610000 / 674043 embeddings...\n",
      "Uploaded 620000 / 674043 embeddings...\n",
      "Uploaded 630000 / 674043 embeddings...\n",
      "Uploaded 640000 / 674043 embeddings...\n",
      "Uploaded 650000 / 674043 embeddings...\n",
      "Uploaded 660000 / 674043 embeddings...\n",
      "Uploaded 670000 / 674043 embeddings...\n",
      "Successfully uploaded 674043 embeddings to Qdrant!\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client import models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Qdrant client\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://3ed0dfdc-3f3f-4424-9123-87025b9842df.us-east4-0.gcp.cloud.qdrant.io\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.cnfVaM94fTBzg_LyAnq_Ip1mGLX7WlCy44QqoJNJhzY\",\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "COLLECTION_NAME = \"track_sparse_embeddings\"\n",
    "\n",
    "# Create collection with sparse vectors\n",
    "#if not qdrant_client.collection_exists(COLLECTION_NAME):\n",
    "qdrant_client.recreate_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config={},  # Empty dict for dense vectors\n",
    "        sparse_vectors_config={\n",
    "            \"sparse_vector\": models.SparseVectorParams(\n",
    "                index=models.SparseIndexParams()\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "#print(f\"Created collection '{COLLECTION_NAME}'\")\n",
    "#else:\n",
    "#print(f\"Collection '{COLLECTION_NAME}' already exists\")\n",
    "\n",
    "# Convert TF-IDF sparse matrix to Qdrant SparseVector format\n",
    "def convert_to_qdrant_sparse(sparse_matrix_row):\n",
    "    \"\"\"Convert scipy sparse matrix row to Qdrant SparseVector format\"\"\"\n",
    "    cx = sparse_matrix_row.tocoo()\n",
    "    indices = cx.col.astype(np.uint32)  # Qdrant expects uint32 for indices\n",
    "    values = cx.data.astype(np.float32)  # Values as float32\n",
    "    return models.SparseVector(\n",
    "        indices=indices.tolist(),\n",
    "        values=values.tolist()\n",
    "    )\n",
    "\n",
    "# Upload embeddings to Qdrant (do this once)\n",
    "print(\"Uploading embeddings to Qdrant...\")\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "for i in range(0, len(data_dedup), BATCH_SIZE):\n",
    "    batch_points = []\n",
    "    for j in range(i, min(i + BATCH_SIZE, len(data_dedup))):\n",
    "        sparse_vec = convert_to_qdrant_sparse(sparse_embeddings[j])\n",
    "        \n",
    "        batch_points.append(\n",
    "            PointStruct(\n",
    "                id=j,\n",
    "                vector={\"sparse_vector\": sparse_vec},  # Use models.SparseVector\n",
    "                payload={\n",
    "                    \"track_name\": data_dedup.iloc[j]['track_name'],\n",
    "                    \"artist_name\": data_dedup.iloc[j]['artist_name']\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    qdrant_client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=batch_points\n",
    "    )\n",
    "    \n",
    "    if (i // BATCH_SIZE + 1) % 10 == 0:\n",
    "        print(f\"Uploaded {i + BATCH_SIZE} / {len(data_dedup)} embeddings...\")\n",
    "\n",
    "print(f\"Successfully uploaded {len(data_dedup)} embeddings to Qdrant!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3133e31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing search...\n",
      "1. Le mime by Ben Adams (score: 0.4648)\n",
      "2. Momentum by Truckfighters (score: 0.4210)\n",
      "3. Momentum by The Hush Sound (score: 0.4210)\n",
      "4. Momentum by Audiomachine (score: 0.4210)\n",
      "5. Momentum by Dimitri Vegas & Like Mike (score: 0.4210)\n"
     ]
    }
   ],
   "source": [
    "# Fast search function - UPDATED\n",
    "def search_qdrant(query, top_k=10):\n",
    "    \"\"\"Fast search using Qdrant sparse vectors\"\"\"\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    sparse_query = convert_to_qdrant_sparse(query_vector[0])\n",
    "    \n",
    "    # Use query_points instead of deprecated search method\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=sparse_query,  # Direct SparseVector, not tuple\n",
    "        limit=top_k,\n",
    "        using=\"sparse_vector\",  # Specify which sparse vector to use\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    return [\n",
    "        {\n",
    "            'track_name': hit.payload['track_name'],\n",
    "            'artist_name': hit.payload['artist_name'],\n",
    "            'similarity_score': hit.score\n",
    "        }\n",
    "        for hit in results.points\n",
    "    ]\n",
    "\n",
    "# Test search\n",
    "print(\"\\nTesting search...\")\n",
    "results = search_qdrant(\"mimentums\", top_k=5)\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['track_name']} by {result['artist_name']} (score: {result['similarity_score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88d1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f11464c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344a420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Smart Shuffle",
   "language": "python",
   "name": "smart-shuffle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
