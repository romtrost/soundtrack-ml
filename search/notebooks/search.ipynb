{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "15017db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08972a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>album_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>Money Longer</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>Lil Uzi Vert Vs. The World</td>\n",
       "      <td>198944</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>Broccoli (feat. Lil Yachty)</td>\n",
       "      <td>DRAM</td>\n",
       "      <td>Big Baby DRAM</td>\n",
       "      <td>225205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>Still Here</td>\n",
       "      <td>Drake</td>\n",
       "      <td>Views</td>\n",
       "      <td>189853</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>You Was Right</td>\n",
       "      <td>Lil Uzi Vert</td>\n",
       "      <td>Lil Uzi Vert Vs. The World</td>\n",
       "      <td>163944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61000</td>\n",
       "      <td>glow</td>\n",
       "      <td>Don't Hurt Me</td>\n",
       "      <td>DJ Mustard</td>\n",
       "      <td>Don't Hurt Me</td>\n",
       "      <td>192995</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playlist_id playlist_name                   track_name   artist_name  \\\n",
       "0        61000          glow                 Money Longer  Lil Uzi Vert   \n",
       "1        61000          glow  Broccoli (feat. Lil Yachty)          DRAM   \n",
       "2        61000          glow                   Still Here         Drake   \n",
       "3        61000          glow                You Was Right  Lil Uzi Vert   \n",
       "4        61000          glow                Don't Hurt Me    DJ Mustard   \n",
       "\n",
       "                   album_name  duration_ms  pos  \n",
       "0  Lil Uzi Vert Vs. The World       198944    0  \n",
       "1               Big Baby DRAM       225205    1  \n",
       "2                       Views       189853    2  \n",
       "3  Lil Uzi Vert Vs. The World       163944    3  \n",
       "4               Don't Hurt Me       192995    4  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/romain/Documents/Personal/Projects/Soundtrack_ML/soundtrack-ml/search/data/processed/track_playlist/tracks_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "def tokenize(text, n=3):\n",
    "    tokens = []\n",
    "    for n_gram_size in range(3, 6):  # 3, 4, 5\n",
    "        tokens.extend([text[i:i+n_gram_size] for i in range(len(text)-n_gram_size+1)])\n",
    "    return tokens\n",
    "\n",
    "# Convert BM25 scores to Qdrant SparseVector format\n",
    "def convert_bm25_to_qdrant_sparse(doc_tokens, vocab):\n",
    "    \"\"\"Convert BM25 document to Qdrant SparseVector format\"\"\"\n",
    "    from collections import Counter\n",
    "    token_counts = Counter(doc_tokens)\n",
    "    \n",
    "    indices = []\n",
    "    values = []\n",
    "    for token, count in token_counts.items():\n",
    "        if token in vocab:\n",
    "            indices.append(np.uint32(vocab[token]))\n",
    "            values.append(np.float32(count))\n",
    "    \n",
    "    return models.SparseVector(\n",
    "        indices=[np.uint32(i) for i in indices],\n",
    "        values=[np.float32(v) for v in values]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff8377",
   "metadata": {},
   "source": [
    "### Track BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ccaa38ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of tracks: 6615091\n",
      "Deduplicated number of tracks: 674043\n",
      "Created BM25 index\n",
      "Number of tracks: 674043\n",
      "Number of documents in corpus: 674043\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate tracks based on track_name and artist_name\n",
    "tracks_dedup = data.drop_duplicates(subset=['track_name', 'artist_name'], keep='first').reset_index(drop=True)\n",
    "print(f\"Original number of tracks: {len(data)}\")\n",
    "print(f\"Deduplicated number of tracks: {len(tracks_dedup)}\")\n",
    "\n",
    "# Prepare corpus with character n-grams\n",
    "track_names = tracks_dedup['track_name'].fillna('').astype(str)\n",
    "corpus_track = [tokenize(track_name, 3) for track_name in track_names]\n",
    "#print(corpus[0:30])\n",
    "\n",
    "# Create sparse vector embeddings using BM25\n",
    "bm25_track = BM25Okapi(corpus_track)\n",
    "\n",
    "print(f\"Created BM25 index\")\n",
    "print(f\"Number of tracks: {len(track_names)}\")\n",
    "print(f\"Number of documents in corpus: {len(corpus_track)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "530ec60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875149/2436640388.py:15: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built vocabulary with 1084365 unique tokens\n",
      "Uploading embeddings to Qdrant...\n",
      "Uploaded 10000 / 674043 embeddings...\n",
      "Uploaded 20000 / 674043 embeddings...\n",
      "Uploaded 30000 / 674043 embeddings...\n",
      "Uploaded 40000 / 674043 embeddings...\n",
      "Uploaded 50000 / 674043 embeddings...\n",
      "Uploaded 60000 / 674043 embeddings...\n",
      "Uploaded 70000 / 674043 embeddings...\n",
      "Uploaded 80000 / 674043 embeddings...\n",
      "Uploaded 90000 / 674043 embeddings...\n",
      "Uploaded 100000 / 674043 embeddings...\n",
      "Uploaded 110000 / 674043 embeddings...\n",
      "Uploaded 120000 / 674043 embeddings...\n",
      "Uploaded 130000 / 674043 embeddings...\n",
      "Uploaded 140000 / 674043 embeddings...\n",
      "Uploaded 150000 / 674043 embeddings...\n",
      "Uploaded 160000 / 674043 embeddings...\n",
      "Uploaded 170000 / 674043 embeddings...\n",
      "Uploaded 180000 / 674043 embeddings...\n",
      "Uploaded 190000 / 674043 embeddings...\n",
      "Uploaded 200000 / 674043 embeddings...\n",
      "Uploaded 210000 / 674043 embeddings...\n",
      "Uploaded 220000 / 674043 embeddings...\n",
      "Uploaded 230000 / 674043 embeddings...\n",
      "Uploaded 240000 / 674043 embeddings...\n",
      "Uploaded 250000 / 674043 embeddings...\n",
      "Uploaded 260000 / 674043 embeddings...\n",
      "Uploaded 270000 / 674043 embeddings...\n",
      "Uploaded 280000 / 674043 embeddings...\n",
      "Uploaded 290000 / 674043 embeddings...\n",
      "Uploaded 300000 / 674043 embeddings...\n",
      "Uploaded 310000 / 674043 embeddings...\n",
      "Uploaded 320000 / 674043 embeddings...\n",
      "Uploaded 330000 / 674043 embeddings...\n",
      "Uploaded 340000 / 674043 embeddings...\n",
      "Uploaded 350000 / 674043 embeddings...\n",
      "Uploaded 360000 / 674043 embeddings...\n",
      "Uploaded 370000 / 674043 embeddings...\n",
      "Uploaded 380000 / 674043 embeddings...\n",
      "Uploaded 390000 / 674043 embeddings...\n",
      "Uploaded 400000 / 674043 embeddings...\n",
      "Uploaded 410000 / 674043 embeddings...\n",
      "Uploaded 420000 / 674043 embeddings...\n",
      "Uploaded 430000 / 674043 embeddings...\n",
      "Uploaded 440000 / 674043 embeddings...\n",
      "Uploaded 450000 / 674043 embeddings...\n",
      "Uploaded 460000 / 674043 embeddings...\n",
      "Uploaded 470000 / 674043 embeddings...\n",
      "Uploaded 480000 / 674043 embeddings...\n",
      "Uploaded 490000 / 674043 embeddings...\n"
     ]
    },
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 502 (Bad Gateway)\nRaw response content:\nb'Bad Gateway'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedResponse\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     44\u001b[39m     sparse_vec = convert_bm25_to_qdrant_sparse(corpus_track[j], vocab_track)\n\u001b[32m     46\u001b[39m     batch_points.append(\n\u001b[32m     47\u001b[39m         PointStruct(\n\u001b[32m     48\u001b[39m             \u001b[38;5;28mid\u001b[39m=j,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m         )\n\u001b[32m     55\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43mqdrant_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCOLLECTION_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_points\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (i // BATCH_SIZE + \u001b[32m1\u001b[39m) % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUploaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mBATCH_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tracks_dedup)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m embeddings...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/Projects/Soundtrack_ML/soundtrack-ml/smart_shuffle/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_client.py:1633\u001b[39m, in \u001b[36mQdrantClient.upsert\u001b[39m\u001b[34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[39m\n\u001b[32m   1626\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1627\u001b[39m         points = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m   1628\u001b[39m             \u001b[38;5;28mself\u001b[39m._embed_models(\n\u001b[32m   1629\u001b[39m                 points, is_query=\u001b[38;5;28;01mFalse\u001b[39;00m, batch_size=\u001b[38;5;28mself\u001b[39m.local_inference_batch_size\n\u001b[32m   1630\u001b[39m             )\n\u001b[32m   1631\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1635\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1636\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1637\u001b[39m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1638\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshard_key_selector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/Projects/Soundtrack_ML/soundtrack-ml/smart_shuffle/.venv/lib/python3.13/site-packages/qdrant_client/qdrant_remote.py:1911\u001b[39m, in \u001b[36mQdrantRemote.upsert\u001b[39m\u001b[34m(self, collection_name, points, wait, ordering, shard_key_selector, **kwargs)\u001b[39m\n\u001b[32m   1908\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(points, models.Batch):\n\u001b[32m   1909\u001b[39m     points = models.PointsBatch(batch=points, shard_key=shard_key_selector)\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m http_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoints_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1916\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.result\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m http_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mUpsert returned None result\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1918\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m http_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/Projects/Soundtrack_ML/soundtrack-ml/smart_shuffle/.venv/lib/python3.13/site-packages/qdrant_client/http/api/points_api.py:987\u001b[39m, in \u001b[36mSyncPointsApi.upsert_points\u001b[39m\u001b[34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[39m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mupsert_points\u001b[39m(\n\u001b[32m    978\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    979\u001b[39m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    982\u001b[39m     point_insert_operations: m.PointInsertOperations = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    983\u001b[39m ) -> m.InlineResponse2006:\n\u001b[32m    984\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[33;03m    Perform insert + updates on points. If point with given ID already exists - it will be overwritten.\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_for_upsert_points\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m        \u001b[49m\u001b[43mordering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mordering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoint_insert_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/Projects/Soundtrack_ML/soundtrack-ml/smart_shuffle/.venv/lib/python3.13/site-packages/qdrant_client/http/api/points_api.py:512\u001b[39m, in \u001b[36m_PointsApi._build_for_upsert_points\u001b[39m\u001b[34m(self, collection_name, wait, ordering, point_insert_operations)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[32m    511\u001b[39m     headers[\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInlineResponse2006\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[33;43m/points\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/Projects/Soundtrack_ML/soundtrack-ml/smart_shuffle/.venv/lib/python3.13/site-packages/qdrant_client/http/api_client.py:95\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, type_, method, url, path_params, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     94\u001b[39m request = \u001b[38;5;28mself\u001b[39m._client.build_request(method, url, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/Projects/Soundtrack_ML/soundtrack-ml/smart_shuffle/.venv/lib/python3.13/site-packages/qdrant_client/http/api_client.py:130\u001b[39m, in \u001b[36mApiClient.send\u001b[39m\u001b[34m(self, request, type_)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse.for_response(response)\n",
      "\u001b[31mUnexpectedResponse\u001b[39m: Unexpected Response: 502 (Bad Gateway)\nRaw response content:\nb'Bad Gateway'"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client import models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Qdrant client\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://3ed0dfdc-3f3f-4424-9123-87025b9842df.us-east4-0.gcp.cloud.qdrant.io\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.cnfVaM94fTBzg_LyAnq_Ip1mGLX7WlCy44QqoJNJhzY\",\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "COLLECTION_NAME = \"track_embeddings_bm25\"\n",
    "\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={},  # Empty dict for dense vectors\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            index=models.SparseIndexParams(),\n",
    "            modifier=models.Modifier.IDF  # Enable IDF for proper BM25 scoring\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Build vocabulary from corpus\n",
    "vocab_track = {}\n",
    "vocab_idx_track = 0\n",
    "for doc in corpus_track:\n",
    "    for token in doc:\n",
    "        if token not in vocab_track:\n",
    "            vocab_track[token] = vocab_idx_track\n",
    "            vocab_idx_track += 1\n",
    "\n",
    "print(f\"Built vocabulary with {len(vocab_track)} unique tokens\")\n",
    "\n",
    "# Upload embeddings to Qdrant (do this once)\n",
    "print(\"Uploading embeddings to Qdrant...\")\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "for i in range(0, len(tracks_dedup), BATCH_SIZE):\n",
    "    batch_points = []\n",
    "    for j in range(i, min(i + BATCH_SIZE, len(tracks_dedup))):\n",
    "        sparse_vec = convert_bm25_to_qdrant_sparse(corpus_track[j], vocab_track)\n",
    "        \n",
    "        batch_points.append(\n",
    "            PointStruct(\n",
    "                id=j,\n",
    "                vector={\"bm25\": sparse_vec},\n",
    "                payload={\n",
    "                    \"track_name\": tracks_dedup.iloc[j]['track_name'],\n",
    "                    \"artist_name\": tracks_dedup.iloc[j]['artist_name']\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    qdrant_client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=batch_points\n",
    "    )\n",
    "    \n",
    "    if (i // BATCH_SIZE + 1) % 10 == 0:\n",
    "        print(f\"Uploaded {i + BATCH_SIZE} / {len(tracks_dedup)} embeddings...\")\n",
    "\n",
    "print(f\"Successfully uploaded {len(tracks_dedup)} embeddings to Qdrant!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c22085c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search results for: 'Don Diablo'\n",
      "1. Don't - Don Diablo Remix - Ed Sheeran (score: 154.6175)\n",
      "2. Tunnel Vision - Don Diablo Edit - Zonderling (score: 153.7905)\n",
      "3. Ready For The Weekend ft. Ayah Marar - Don Diablo Remix - R3HAB (score: 150.2873)\n",
      "4. Secrets - Don Diablo Remix - Tiësto (score: 150.2873)\n",
      "5. Good Grief - Don Diablo Remix - Bastille (score: 150.2873)\n",
      "6. Belong to the Rhythm - Don Diablo Edit - King Arthur (score: 150.2873)\n",
      "7. Give Me A Try (Don Diablo Remix) - The Wombats (score: 150.2873)\n",
      "8. Back To You - Don Diablo Edit - Ryan Blyth (score: 150.2873)\n",
      "9. Ready For The Weekend ft. Ayah Marar - Don Diablo Remix Edit - R3HAB (score: 150.2873)\n",
      "10. Kanye - Don Diablo Remix - The Chainsmokers (score: 150.2873)\n",
      "11. Something Just Like This - Don Diablo Remix - The Chainsmokers (score: 150.2873)\n",
      "12. Ghosttown - Don Diablo Remix - Madonna (score: 150.2873)\n",
      "13. Secrets - Don Diablo’s VIP Mix - Tiësto (score: 150.2873)\n",
      "14. Close My Eyes - Don Diablo Edit - Corderoy (score: 150.2873)\n",
      "15. Let Me Love You - Don Diablo Remix - DJ Snake (score: 150.2873)\n",
      "16. Love On The Brain - Don Diablo Remix - Rihanna (score: 150.2873)\n",
      "17. All Cried Out (feat. Alex Newell) - Don Diablo Remix - Blonde (score: 150.2873)\n",
      "18. Children Of A Miracle - Don Diablo VIP Mix - Don Diablo (score: 150.2873)\n",
      "19. Make Me Feel Better - Don Diablo & CID Radio Edit - Alex Adair (score: 150.2873)\n",
      "20. Never Let You Go (feat. Foy Vance) - Don Diablo Remix - Rudimental (score: 150.2873)\n",
      "21. El Ganon Diablo (The Legend of Zelda) - Blind (score: 128.7931)\n",
      "22. Diabelli Variations - 33 Variations on a Waltz by Anton Diabelli, Op. 120: Var. 24 - Fughetta. Andante - Ludwig van Beethoven (score: 108.2049)\n",
      "23. Entre Dios Y El Diablo - Gerardo Ortiz (score: 92.4698)\n",
      "24. Caprici Di Diablo - Yngwie Malmsteen (score: 92.4698)\n",
      "25. De Parranda Con El Diablo - Grupo Exterminador (score: 91.7331)\n",
      "26. El Diablo en una Botella - Con Tololoche - H100 (score: 91.7331)\n",
      "27. Platicando Con El Diablo (feat. Cano & Blunt) - Big Los (score: 91.7331)\n",
      "28. La Pelea Con el Diablo - Octavio Mesa Y Su Conjunto (score: 91.7331)\n",
      "29. Al Diablo Con Los Guapos aka No Me Supiste Querer - K-Paz De La Sierra (score: 91.7331)\n",
      "30. La Pelea Con el Diablo - Octavio Mesa (score: 91.7331)\n",
      "31. El Diablo en una Botella - Alvaro Montes y Su Aguila Norteña (score: 88.2299)\n",
      "32. Vous les femmes (Pobre Diablo) - Arno (score: 88.2299)\n",
      "33. Cosas Del Diablo - Tito Y Su Torbellino (score: 88.2299)\n",
      "34. El Diablo en Una Botella - Tito Y Su Torbellino (score: 88.2299)\n",
      "35. La Caspa Del Diablo - Los Originales De San Juan (score: 88.2299)\n",
      "36. Mt. Diablo - The Story So Far (score: 88.2299)\n",
      "37. No Diablo - Umphrey's McGee (score: 88.2299)\n",
      "38. Pobre Diablo - Emmanuel (score: 88.2299)\n",
      "39. Pobre Diablo - Julio Iglesias (score: 88.2299)\n",
      "40. (El Camino del Diablo) - Rupa & the April Fishes (score: 88.2299)\n",
      "41. Dios el Diablo y Yo - Iluminatik (score: 88.2299)\n",
      "42. El Diablo - Mon Laferte (score: 88.2299)\n",
      "43. Que Me Lleve El Diablo - En Vivo Desde Monterrey/2010 - Los Huracanes del Norte (score: 88.2299)\n",
      "44. Que Me Lleve el Diablo - Adolfo Urias (score: 88.2299)\n",
      "45. Pobre Diablo - El Jeffrey (score: 88.2299)\n",
      "46. El Diablotun Tun - Miguelito Cuni (score: 88.2299)\n",
      "47. Que Me Lleve El Diablo - En Vivo - Pesado (score: 88.2299)\n",
      "48. No Diablo (Kondrath 80s Remix) - Umphrey's McGee (score: 88.2299)\n",
      "49. El Diablo - Nonpoint (score: 88.2299)\n",
      "50. Ni Diablo Ni Santo - Julión Álvarez y su Norteño Banda (score: 88.2299)\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = \"track_embeddings_bm25\"\n",
    "\n",
    "# Search function\n",
    "def search_tracks(query, top_k=10):\n",
    "    \"\"\"Search for tracks using BM25 sparse vectors\"\"\"\n",
    "    # Tokenize query\n",
    "    query_tokens = tokenize(query)\n",
    "    \n",
    "    # Convert query to sparse vector\n",
    "    query_sparse = convert_bm25_to_qdrant_sparse(query_tokens, vocab_track)\n",
    "    \n",
    "    # Search in Qdrant\n",
    "    search_results = qdrant_client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=query_sparse,\n",
    "        limit=top_k,\n",
    "        using=\"bm25\",\n",
    "        with_payload=True\n",
    "    ).points\n",
    "    \n",
    "    # Format results\n",
    "    results = []\n",
    "    for hit in search_results:\n",
    "        results.append({\n",
    "            \"track_name\": hit.payload[\"track_name\"],\n",
    "            \"artist_name\": hit.payload[\"artist_name\"],\n",
    "            \"score\": hit.score\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test search\n",
    "query = \"Don Diablo\"\n",
    "results = search_tracks(query, top_k=50)\n",
    "print(f\"\\nSearch results for: '{query}'\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['track_name']} - {result['artist_name']} (score: {result['score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4bdc95",
   "metadata": {},
   "source": [
    "### Artist BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce88d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of tracks: 6615091\n",
      "Deduplicated number of artists: 108294\n",
      "Created BM25 index\n",
      "Number of artists: 108294\n",
      "Number of documents in corpus: 108294\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "# Deduplicate artists based on artist_name\n",
    "artists_dedup = data.drop_duplicates(subset=['artist_name'], keep='first').reset_index(drop=True)\n",
    "print(f\"Original number of tracks: {len(data)}\")\n",
    "print(f\"Deduplicated number of artists: {len(artists_dedup)}\")\n",
    "\n",
    "# Prepare corpus with character n-grams\n",
    "artist_names = artists_dedup['artist_name'].fillna('').astype(str)\n",
    "corpus_artist = [tokenize(artist_name, 3) for artist_name in artist_names]\n",
    "#print(corpus[0:30])\n",
    "\n",
    "# Create sparse vector embeddings using BM25\n",
    "bm25_artist = BM25Okapi(corpus_artist)\n",
    "\n",
    "print(f\"Created BM25 index\")\n",
    "print(f\"Number of artists: {len(artist_names)}\")\n",
    "print(f\"Number of documents in corpus: {len(corpus_artist)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f11464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_875149/272050797.py:15: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built vocabulary with 422941 unique tokens\n",
      "Uploading artist embeddings to Qdrant...\n",
      "Uploaded 10000 / 108294 artist embeddings...\n",
      "Uploaded 20000 / 108294 artist embeddings...\n",
      "Uploaded 30000 / 108294 artist embeddings...\n",
      "Uploaded 40000 / 108294 artist embeddings...\n",
      "Uploaded 50000 / 108294 artist embeddings...\n",
      "Uploaded 60000 / 108294 artist embeddings...\n",
      "Uploaded 70000 / 108294 artist embeddings...\n",
      "Uploaded 80000 / 108294 artist embeddings...\n",
      "Uploaded 90000 / 108294 artist embeddings...\n",
      "Uploaded 100000 / 108294 artist embeddings...\n",
      "Successfully uploaded 108294 artist embeddings to Qdrant!\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client import models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Qdrant client\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://3ed0dfdc-3f3f-4424-9123-87025b9842df.us-east4-0.gcp.cloud.qdrant.io\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.cnfVaM94fTBzg_LyAnq_Ip1mGLX7WlCy44QqoJNJhzY\",\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "COLLECTION_NAME = \"artist_embeddings_bm25\"\n",
    "\n",
    "qdrant_client.recreate_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={},  # Empty dict for dense vectors\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            index=models.SparseIndexParams(),\n",
    "            modifier=models.Modifier.IDF  # Enable IDF for proper BM25 scoring\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Build vocabulary from corpus\n",
    "vocab_artist = {}\n",
    "vocab_idx_artist = 0\n",
    "for doc in corpus_artist:\n",
    "    for token in doc:\n",
    "        if token not in vocab_artist:\n",
    "            vocab_artist[token] = vocab_idx_artist\n",
    "            vocab_idx_artist += 1\n",
    "\n",
    "print(f\"Built vocabulary with {len(vocab_artist)} unique tokens\")\n",
    "\n",
    "# Upload embeddings to Qdrant (do this once)\n",
    "print(\"Uploading artist embeddings to Qdrant...\")\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "for i in range(0, len(artists_dedup), BATCH_SIZE):\n",
    "    batch_points = []\n",
    "    for j in range(i, min(i + BATCH_SIZE, len(artists_dedup))):\n",
    "        sparse_vec = convert_bm25_to_qdrant_sparse(corpus_artist[j], vocab_artist)\n",
    "        \n",
    "        batch_points.append(\n",
    "            PointStruct(\n",
    "                id=j,\n",
    "                vector={\"bm25\": sparse_vec},\n",
    "                payload={\n",
    "                    \"artist_name\": artists_dedup.iloc[j]['artist_name']\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    qdrant_client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=batch_points\n",
    "    )\n",
    "    \n",
    "    if (i // BATCH_SIZE + 1) % 10 == 0:\n",
    "        print(f\"Uploaded {i + BATCH_SIZE} / {len(artists_dedup)} artist embeddings...\")\n",
    "\n",
    "print(f\"Successfully uploaded {len(artists_dedup)} artist embeddings to Qdrant!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d344a420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search results for: 'Drake'\n",
      "1. Drake Bell (score: 42.2382)\n",
      "2. Drakensang (score: 42.2382)\n",
      "3. Drake White (score: 42.2382)\n",
      "4. Drakeford (score: 42.2382)\n",
      "5. Alfred Drake (score: 42.2382)\n",
      "6. Romeo Santos Ft Drake (score: 42.2382)\n",
      "7. Ludwig Von Drake (score: 42.2382)\n",
      "8. Julius Drake, Ian Bostridge (score: 42.2382)\n",
      "9. Dark Drake (score: 42.2382)\n",
      "10. DJ Florence Drake (score: 42.2382)\n",
      "11. Nick J Drake (score: 42.2382)\n",
      "12. Christopher Drake (score: 42.2382)\n",
      "13. Pete Drake (score: 42.2382)\n",
      "14. Drakeo the Ruler (score: 42.2382)\n",
      "15. Molly Drake (score: 42.2382)\n",
      "16. Drake (score: 42.2382)\n",
      "17. DJ Fetty Drake (score: 42.2382)\n",
      "18. Grace, Drake, & Warbucks' Staff (score: 42.2382)\n",
      "19. Nick Drake (score: 42.2382)\n",
      "20. JonDrake (score: 42.2382)\n",
      "21. Martin Charnin as Drake, Shelly Burch as Grace, & Warbucks' Staff (score: 42.2382)\n",
      "22. Drake Chisholm (score: 42.2382)\n",
      "23. Eleni Drake (score: 42.2382)\n",
      "24. Dusty Drake (score: 42.2382)\n",
      "25. Jamie Drake (score: 42.2382)\n",
      "26. The Fallen Drakes (score: 42.2382)\n",
      "27. Destiny Drake (score: 42.2382)\n",
      "28. Drako (score: 21.3475)\n",
      "29. Fani Drakopoulou (score: 21.3475)\n",
      "30. Drakum (score: 21.3475)\n",
      "31. Drakulas (score: 21.3475)\n",
      "32. Drakkar Nowhere (score: 21.3475)\n",
      "33. Drakkar Sauna (score: 21.3475)\n",
      "34. J-Kraken (score: 19.3335)\n",
      "35. Haraket (score: 19.3335)\n",
      "36. Kraked Unit (score: 19.3335)\n",
      "37. Will Fraker (score: 19.3335)\n",
      "38. Bluedrake42 (score: 19.3335)\n",
      "39. Stakka & Skynet, Stakka & K. Tee, Kraken, Profound Noize, (score: 19.3335)\n",
      "40. Brakes (score: 19.3335)\n",
      "41. Moonraker (score: 19.3335)\n",
      "42. Kraken (score: 19.3335)\n",
      "43. Braken (score: 19.3335)\n",
      "44. Dagny,Richard Craker,Chris Porter (score: 19.3335)\n",
      "45. Daniel Trakell (score: 19.3335)\n",
      "46. Cosmo Sheldrake (score: 19.3335)\n",
      "47. Turin Brakes (score: 19.3335)\n",
      "48. Irakere (score: 19.3335)\n",
      "49. Stonebraker (score: 19.3335)\n",
      "50. Here Comes The Kraken (score: 19.3335)\n"
     ]
    }
   ],
   "source": [
    "# Search function\n",
    "def search_artists(query, top_k=10):\n",
    "    \"\"\"Search for artists using BM25 sparse vectors\"\"\"\n",
    "    # Tokenize query\n",
    "    query_tokens = tokenize(query)\n",
    "    \n",
    "    # Convert query to sparse vector\n",
    "    query_sparse = convert_bm25_to_qdrant_sparse(query_tokens, vocab_artist)\n",
    "    \n",
    "    # Search in Qdrant\n",
    "    search_results = qdrant_client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=query_sparse,\n",
    "        limit=top_k,\n",
    "        using=\"bm25\",\n",
    "        with_payload=True\n",
    "    ).points\n",
    "    \n",
    "    # Format results\n",
    "    results = []\n",
    "    for hit in search_results:\n",
    "        results.append({\n",
    "            \"artist_name\": hit.payload[\"artist_name\"],\n",
    "            \"score\": hit.score\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test search\n",
    "query = \"Drake\"\n",
    "results = search_artists(query, top_k=50)\n",
    "print(f\"\\nSearch results for: '{query}'\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['artist_name']} (score: {result['score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a802058",
   "metadata": {},
   "source": [
    "### Complete Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e42ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of tracks: 6615091\n",
      "Deduplicated number of tracks: 5416504\n",
      "Sample combined text: Money Longer by Lil Uzi Vert from Lil Uzi Vert Vs. The World in playlist glow\n",
      "Creating dense embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb196de0cbd488d93c337d6767ebbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/169266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize sentence transformer model for dense embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Deduplicate tracks to get unique combinations\n",
    "tracks_dedup = data.drop_duplicates(subset=['track_name', 'artist_name', 'album_name', 'playlist_name'], keep='first').reset_index(drop=True)\n",
    "print(f\"Original number of tracks: {len(data)}\")\n",
    "print(f\"Deduplicated number of tracks: {len(tracks_dedup)}\")\n",
    "\n",
    "# Create combined text for each track (track + artist + album + playlist)\n",
    "combined_texts = []\n",
    "for idx, row in tracks_dedup.iterrows():\n",
    "    track_name = str(row['track_name']) if pd.notna(row['track_name']) else ''\n",
    "    artist_name = str(row['artist_name']) if pd.notna(row['artist_name']) else ''\n",
    "    album_name = str(row['album_name']) if pd.notna(row['album_name']) else ''\n",
    "    playlist_name = str(row['playlist_name']) if pd.notna(row['playlist_name']) else ''\n",
    "    \n",
    "    combined_text = f\"{track_name} by {artist_name} from {album_name} in playlist {playlist_name}\"\n",
    "    combined_texts.append(combined_text)\n",
    "\n",
    "print(f\"Sample combined text: {combined_texts[0]}\")\n",
    "\n",
    "# Create dense embeddings\n",
    "print(\"Creating dense embeddings...\")\n",
    "dense_embeddings = model.encode(combined_texts, show_progress_bar=True, batch_size=32)\n",
    "\n",
    "print(f\"Created dense embeddings\")\n",
    "print(f\"Number of tracks: {len(tracks_dedup)}\")\n",
    "print(f\"Embedding dimension: {dense_embeddings.shape[1]}\")\n",
    "print(f\"Embeddings shape: {dense_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8725d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client import models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Qdrant client\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://3ed0dfdc-3f3f-4424-9123-87025b9842df.us-east4-0.gcp.cloud.qdrant.io\",\n",
    "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.cnfVaM94fTBzg_LyAnq_Ip1mGLX7WlCy44QqoJNJhzY\",\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "COLLECTION_NAME = \"combined_embeddings_dense\"\n",
    "\n",
    "# Check if collection exists, if so delete it\n",
    "if qdrant_client.collection_exists(COLLECTION_NAME):\n",
    "    qdrant_client.delete_collection(COLLECTION_NAME)\n",
    "\n",
    "# Create collection with dense vectors\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\n",
    "        \"all-MiniLM-L6-v2\": models.VectorParams(\n",
    "            size=dense_embeddings.shape[1],\n",
    "            distance=models.Distance.COSINE\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "# Upload dense embeddings to Qdrant\n",
    "print(\"Uploading dense embeddings to Qdrant...\")\n",
    "BATCH_SIZE = 1000\n",
    "\n",
    "for i in range(0, len(tracks_dedup), BATCH_SIZE):\n",
    "    batch_points = []\n",
    "    for j in range(i, min(i + BATCH_SIZE, len(tracks_dedup))):\n",
    "        batch_points.append(\n",
    "            PointStruct(\n",
    "                id=j,\n",
    "                vector={\n",
    "                    \"all-MiniLM-L6-v2\": dense_embeddings[j].tolist()\n",
    "                },\n",
    "                payload={\n",
    "                    \"track_name\": tracks_dedup.iloc[j]['track_name'],\n",
    "                    \"artist_name\": tracks_dedup.iloc[j]['artist_name'],\n",
    "                    \"album_name\": tracks_dedup.iloc[j]['album_name'],\n",
    "                    \"playlist_name\": tracks_dedup.iloc[j]['playlist_name']\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    qdrant_client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=batch_points\n",
    "    )\n",
    "    \n",
    "    if (i // BATCH_SIZE + 1) % 10 == 0:\n",
    "        print(f\"Uploaded {i + BATCH_SIZE} / {len(tracks_dedup)} embeddings...\")\n",
    "\n",
    "print(f\"Successfully uploaded {len(tracks_dedup)} dense embeddings to Qdrant!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Smart Shuffle",
   "language": "python",
   "name": "smart-shuffle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
